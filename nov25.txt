    1  sudo hostnamectl hostname kubeai.example.com
    2  sudo reboot
    3  sudo apt install nvidia-cuda-toolkit
    4  sudo dnf install openssh-server
    5  sudo apt install openssh-server
    6  ip a
    7  lspci -k | less
    8  sudo apt install git vim -y
    9  git clone https://github.com/sandervanvugt/cka
   10  cd cka
   11  ls *sh
   12  ./setup-container.sh 
   13  sudo apt install -y wget
   14  sudo apt install -y curl
   15  ping github.com
   16  ./setup-container.sh 
   17  systemctl status containerd
   18  history
   19  ./setup-kubetools.sh 
   20  history
   21  sudo kubeadm init
   22  kubectl get all
   23  kubectl get pods -n kube-system
   24  cat setup-kubetools.sh 
   25  kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml
   26  kubectl get pods -n kube-system
   27  source <(kubectl completion bash)
   28  history
   29  kubectl run testpod --image=nginx
   30  kubectl get pods
   31  kubectl describe pod testpod
   32  kubectl edit node kubeai.example.com 
   33  kubectl get pods
   34  history
   35  ./counter.sh 15
   36  history
   37  cat  /etc/hosts
   38  hostname
   39  sudo vim /etc/hosts
   40  kubectl get all
   41  kubectl edit node kubeai.example.com 
   42  kubectl create deploy testdeploy --image=nginx --replicas=3
   43  kubectl get all
   44  kubectl scale deploy testdeploy --image=4
   45  kubectl scale deploy testdeploy --replicas=4
   46  kubectl delete pod/testpod
   47  kubectl delete deployments.apps testdeploy 
   48  history
   49  kubectl get crd
   50  kubectl api-resources
   51  kubectl get crd
   52  sudo apt install curl gpg apt-transport-https -y
   53  sudo snap install helm --classic
   54  helm --version
   55  helm -h
   56  history | less
   57  helm version
   58  sudo apt install -y ntop
   59  sudo apt install -y nvtop
   60  nvtop
   61  helm repo add nvidia https://nvidia.github.io/gpu-operator
   62  history
   63  helm repo update
   64  kubectl create ns nvidia-gpu-operator
   65  cd 
   66  git clone https://github.com/sandervanvugt/kubeai
   67  cd kubeai/
   68  ls
   69  vim values.yaml 
   70  helm upgrade --install gpu-operator nvidia/gpu-operator --namespace nvidia-gpu-operator -f values.yaml
   71  kubectl -n nvidia-gpu-operator get pods
   72  kubectl -n nvidia-gpu-operator get pods,ds,deploy
   73  cat values.yaml 
   74  history
   75  kubectl -n nvidia-gpu-operator get pods
   76  vim gpu-test.yaml 
   77  kubectl apply -f gpu-test.yaml
   78  kubectl get pods
   79  kubectl describe pod gpu-test
   80  sudo reboot
   81  top
   82  sudo crictl status
   83  sudo crictl ps
   84  source <(kubectl completion bash)
   85  kubectl get pods -n nvidia-gpu-operator 
   86  kubectl get deploy
   87  kubectl get deploy -n nvidia-gpu-operator 
   88  kubectl get ds -n nvidia-gpu-operator 
   89  kubectl get pods
   90  kubectl describe pods gpu-test
   91  kubectl edit node kubeai.example.com 
   92  cd kubeai/
   93  ls
   94  kubectl delete -f gpu-test.yaml 
   95  vim gpu-test.yaml
   96  kubectl apply -f gpu-test.yaml 
   97  kubectl get pods
   98  kubectl logs gpu-test 
   99  history
  100  vim gpu-test.yaml 
  101  kubectl get pods -n nvidia-gpu-operator 
  102  kubectl get node kubeai.example.com -o yaml | grep nvidia
  103  kubectl get node kubeai.example.com -o yaml | less
  104  kubectl get ds -n nvidia-gpu-operator 
  105  kubectl get clusterpolicy
  106  kubectl api-resource | grep clusterpo
  107  kubectl api-resources | grep clusterpo
  108  kubectl get clusterpolicies.nvidia.com -o yaml
  109  ls
  110  vim gpu-test.yaml 
  111  kubectl explain pod.spec | less
  112  vim gpu-test.yaml 
  113  kubectl apply -f gpu-test.yaml 
  114  vim gpu-test.yaml 
  115  kubectl get pods
  116  vim gpu-test.yaml 
  117  kubectl apply -f gpu-test.yaml 
  118  history
  119  kubectl create mydb --image=mariadb --replicas=3
  120  kubectl create deploy mydb --image=mariadb --replicas=3
  121  kubectl get all --selector app=mydb
  122  kubectl logs mydb-5fcf4f6fbb-bclj8 
  123  kubectl create cm -h | less
  124  #kubectl create configmap my-config --from-literal=key1=config1 --from-literal=key2=config2
  125  kubectl create cm mydbcm --from-literal=MARIADB_ROOT_PASSWORD=password
  126  kubectl get cm mydbcm -o yaml
  127  kubectl set env -h | less
  128  #kubectl set env --from=configmap/myconfigmap --prefix=MYSQL_ deployment/myapp
  129  kubectl set env --from=configmap/mydbcm deploy/mydb
  130  kubectl get all --selector app=mydb
  131  history
  132  ls
  133  grep -i configm *
  134  vim nvidia-device-plugin-config.yaml 
  135  kubectl apply -f nvidia-device-plugin-config.yaml 
  136  kubectl edit -n nvidia-gpu-operator clusterpolicies.nvidia.com 
  137  kubectl describe node | grep nvidia.com/gpu
  138  kubectl describe node | less
  139  kubectl get pods
  140  vim ls
  141  ls
  142  vim gpu-test.yaml 
  143  kubectl apply -f gpu-test.yaml 
  144  kubectl get pods
  145  sudo nvtop
  146  /usr/local/nvidia/toolkit/nvidia-container-cli info
  147  history
  148  mkdir -p /opt/models
  149  sudo mkdir -p /opt/models
  150  sudo chmod 777 /opt/models
  151  cat models-pv-pvc.yaml 
  152  kubectl apply -f models-pv-pvc.yaml
  153  kubectl get pv,pvc
  154  kubectl describe pvc models-pvc 
  155  kubectl get pv,pvc
  156  vim download-llm-job.yaml 
  157  kubectl apply -f download-llm-job.yaml
  158  kubectl get all
  159  ls -l /opt/models/
  160  history
  161  history > /tmp/nov25.txt
  162  exit
  163  sudo poweroff
  164  kubectl get pv,pvc
  165  cd kubeai/
  166  git pull
  167  cd ..
  168  mv kubeai kubeai.old
  169  git clone https://github.com/sandervanvugt/kubeai
  170  cd kubeai
  171  ls
  172  vim download-llm-job.yaml 
  173  ls -l /opt/models/
  174  vim llama-deployment.yaml 
  175  kubectl apply -f llama-deployment.yaml 
  176  kubectl get deploy
  177  ls
  178  cat llama-server-test.sh 
  179  ./llama-server-test.sh 
  180  cat llama-server-test.sh 
  181  cat llama-server-test-loop.sh 
  182  ./llama-server-test-loop.sh 
  183  vim llama-server-test-heavier.sh 
  184  ./llama-server-test-heavier.sh 
  185  helm repo list
  186  helm repo update
  187  helm upgrade --install metrics-server metrics-server/metrics-server --namespace kube-system --set-args="{--kubelet-insecure-tls,--kubelet-preferred-address-types=InternalIP}"
  188  helm upgrade --install metrics-server metrics-server/metrics-server --namespace kube-system --set args="{--kubelet-insecure-tls,--kubelet-preferred-address-types=InternalIP}"
  189  kubectl get deploy -n kube-system
  190  kubectl edit deploy -n kube-system metrics-server
  191  kubectl top nodes
  192  kubectl top pods
  193  vim llama-hpa.yaml 
  194  kubectl get pods
  195  kubectl get deploy
  196  kubectl apply -f llama-hpa.yaml 
  197  kubectl get deploy
  198  kubectl get hpa
  199  kubectl get deploy
  200  ./llama-server-test-heavier.sh 
  201  kubectl get hpa
  202  kubectl get pods
  203  source <(kubectl completion bash)
  204  kubectl describe pod llama-server-78697996d4-lk8xh
  205  kubectl logs llama-server-78697996d4-lk8xh
  206  nvidia-smi
  207  ls
  208  kubectl delete -f llama-deployment.yaml 
  209  vim llama-deployment.yaml 
  210  kubectl apply -f llama-deployment.yaml 
  211  kubect get hpa
  212  kubectl get hpa
  213  kubectl get pods
  214  ./llama-server-test-heavier.sh 
  215  kubectl describe node kubeai.example.com | egrep -A6 "Capacity|Allocatable
"
  216  kubectl describe node kubeai.example.com | egrep -A10 "Allocated resources"
  217  kubectl get node kubeai.example.com --show-labels | less
  218  kubectl get node kubeai.example.com -o yaml | less
  219  grep -l 4070
  220  grep -l 4070 *
  221  vim gpu-test.yaml 
  222  kubectl apply -f gpu-test.yaml 
  223  kubectl get pods
  224  kubectl describe  pod gpu-test4
  225  ls
  226  kubectl delete -f llama-deployment.yaml 
  227  vim llama-deploy-with-topologyspread.yaml 
  228  kubectl get nodes kubeai.example.com -o yaml | less
  229  kubectl apply -f llama-deploy-with-topologyspread.yaml 
  230  kubectl get all
  231  kubectl describe pod llama-server-65474c5f66-d4pld 
  232  kubectl get pvc
  233  vim llama-deploy-with-topologyspread.yaml 
  234  kubectl replace -f llama-deploy-with-topologyspread.yaml 
  235  kubectl get all
  236  history
  237  grep PodDis *
  238  kubectl get deploy
  239* 
  240  vim llama-deploy-with-topologyspread.yaml 
  241  kubectl apply -f llama-deploy-with-topologyspread.yaml 
  242  kubectl get deploy --show-labels
  243  vim pdb.yaml
  244  kubectl apply -f pdb.yaml
  245  kubectl describe pdb llama-pdb 
  246  kubectl drain --ignore-daemonsets kubeai.example.com 
  247  kubectl drain --ignore-daemonsets --delete-emptydir-data kubeai.example.com 
  248  kubectl uncordon kubeai.example.com 
  249  ls /opt/models/
  250  history
  251  ../cka/counter.sh 15
  252  history
  253  kubectl get priorityclass
  254  kubectl explain priorityclass
  255  kubectl get priorityclass
  256  vim prioclass.yaml
  257  kubectl apply -f prioclass.yaml 
  258  kubectl get priorityclasses.scheduling.k8s.io 
  259  ls
  260  vim llama-deploy-with-topologyspread.yaml 
  261  kubectl apply -f llama-deploy-with-topologyspread.yaml 
  262  kubectl get all
  263  kubectl describe priorityclasses.scheduling.k8s.io gpu-llm-high 
  264  kubectl describe deployments.apps llama-server | less
  265  helm repo add rook-release https://charts.rook.io/release
  266  helm repo update
  267  help repo list
  268  helm repo list
  269  helm install rook-ceph rook-release/rook-ceph --namespace rook-ceph --create-namespace
  270  kubectl -n rook-ceph get pods
  271  lsblk
  272  sudo xxd /dev/nvme1n1 | less 
  273  sudo gdisk /dev/nvme1n1
  274  ls -l /dev/disk
  275  blkid
  276  ls -l /dev/disk/by-id
  277  lsblk
  278  ls -l /dev/disk/by-id
  279  ls
  280  vim ceph-cluster.yaml 
  281  kubectl apply -f ceph-cluster.yaml 
  282  kubectl -n rook-ceph get cephcluster rook-ceph 
  283  watch kubectl -n rook-ceph get cephcluster rook-ceph 
  284  kubectl -n rook-ceph get cephcluster rook-ceph
  285  kubectl -n rook-ceph get pods
  286  kubectl -n rook-ceph get cephcluster rook-ceph
  287  sudo dd if=/dev/zero of=/bigfile bs=1M count=1024
  288  sudo dd if=/dev/zero of=/bigfile bs=1M count=10240
  289  vim ceph-blockpool.yaml 
  290  kubectl apply -f ceph-blockpool.yaml 
  291  kubectl describe -n rook-ceph cephblockpool 
  292  kubectl get -n rook-ceph cephblockpool 
  293  vim rook-ceph-storageclass.yaml 
  294  kubectl get sc
  295  kubectl apply -f rook-ceph-storageclass.yaml 
  296  kubectl path storageclass rook-ceph-block -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"true"}}}'
  297  kubectl patch storageclass rook-ceph-block -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"true"}}}'
  298  kubectl get sc -o yaml
  299  kubectl get sc
  300  vim ceph-test-pvc.yaml 
  301  kubectl apply -f ceph-test-pvc.yaml 
  302  kubectl get pvc
  303  kubectl describe pvc ceph-test-pvc 
  304  vim ceph-test-pod.yaml 
  305  kubectl apply -f ceph-test-pod.yaml 
  306  kubectl get pvc
  307  kubectl get pods
  308  vim download-llm-on-ceph.yaml 
  309  grep llama-models-pvc *
  310  vim llama-models-pvc.yaml 
  311  kubectl kustomize https://github.com/nginxinc/nginx-gateway-fabric/config/crd/gateway-api/standard?ref=v2.2.1 | kubectl apply -f  -
  312  helm install ngf oci://ghcr.io/nginxinc/charts/nginx-gateway-fabric --create-namespace -n nginx-gateway --set service.type=NodePort
  313  kubectl get pods,svc -n nginx-gateway
  314  kubectl get gc
  315  kubectl edit svc -n nginx-gateway ngf-nginx-gateway-fabric 
  316  kubectl create deploy nginxgw --image=nginx --replicas=3
  317  kubectl expose deploy nginxgw --port=80
  318  cd ../cka
  319  vim http-routing.yaml 
  320  kubectl apply -f http-routing.yaml 
  321  sudo vim /etc/hosts
  322  curl whatever.com:32080
  323  history
  324  history > /tmp/nov25.txt
